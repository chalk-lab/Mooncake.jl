<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Towards AD in Julia: Composition of Rules · Mooncake.jl</title><meta name="title" content="Towards AD in Julia: Composition of Rules · Mooncake.jl"/><meta property="og:title" content="Towards AD in Julia: Composition of Rules · Mooncake.jl"/><meta property="twitter:title" content="Towards AD in Julia: Composition of Rules · Mooncake.jl"/><meta name="description" content="Documentation for Mooncake.jl."/><meta property="og:description" content="Documentation for Mooncake.jl."/><meta property="twitter:description" content="Documentation for Mooncake.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Mooncake.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Mooncake.jl</a></li><li><a class="tocitem" href="../../tutorial/">Tutorial</a></li><li><a class="tocitem" href="../../interface/">Interface</a></li><li><span class="tocitem">Understanding Mooncake.jl</span><ul><li><a class="tocitem" href="../introduction/">Introduction</a></li><li><a class="tocitem" href="../algorithmic_differentiation/">Algorithmic Differentiation</a></li><li><a class="tocitem" href="../rule_system/">Mooncake.jl&#39;s Rule System</a></li><li class="is-active"><a class="tocitem" href>Towards AD in Julia: Composition of Rules</a><ul class="internal"><li><a class="tocitem" href="#A-Motivating-Example"><span>A Motivating Example</span></a></li><li><a class="tocitem" href="#Part-1:-Simple-Compositions-of-Pure-Functions"><span>Part 1: Simple Compositions of Pure Functions</span></a></li><li><a class="tocitem" href="#Part-2:-Functions-of-Pure-Functions"><span>Part 2: Functions of Pure Functions</span></a></li><li><a class="tocitem" href="#Part-3:-Applying-Sequences-of-Mutating-Functions"><span>Part 3: Applying Sequences of Mutating Functions</span></a></li><li><a class="tocitem" href="#Part-4:-Computational-Graphs-of-Mutating-Functions"><span>Part 4: Computational Graphs of Mutating Functions</span></a></li><li><a class="tocitem" href="#Part-5:-Computational-Graphs-of-Mutating-Functions-with-Aliasing"><span>Part 5: Computational Graphs of Mutating Functions with Aliasing</span></a></li></ul></li></ul></li><li><span class="tocitem">Utilities</span><ul><li><a class="tocitem" href="../../utilities/defining_rules/">Defining Rules</a></li><li><a class="tocitem" href="../../utilities/debug_mode/">Debug Mode</a></li><li><a class="tocitem" href="../../utilities/debugging_and_mwes/">Debugging and MWEs</a></li></ul></li><li><span class="tocitem">Developer Documentation</span><ul><li><a class="tocitem" href="../../developer_documentation/running_tests_locally/">Running Tests Locally</a></li><li><a class="tocitem" href="../../developer_documentation/developer_tools/">Developer Tools</a></li><li><a class="tocitem" href="../../developer_documentation/forwards_mode_design/">Forwards-Mode Design</a></li><li><a class="tocitem" href="../../developer_documentation/misc_internals_notes/">Misc. Internals Notes</a></li><li><a class="tocitem" href="../../developer_documentation/internal_docstrings/">Internal Docstrings</a></li></ul></li><li><a class="tocitem" href="../../known_limitations/">Known Limitations</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Understanding Mooncake.jl</a></li><li class="is-active"><a href>Towards AD in Julia: Composition of Rules</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Towards AD in Julia: Composition of Rules</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/compintell/Mooncake.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/compintell/Mooncake.jl/blob/main/docs/src/understanding_mooncake/what_programme_are_you_differentiating.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Towards-AD-in-Julia:-Composition-of-Rules"><a class="docs-heading-anchor" href="#Towards-AD-in-Julia:-Composition-of-Rules">Towards AD in Julia: Composition of Rules</a><a id="Towards-AD-in-Julia:-Composition-of-Rules-1"></a><a class="docs-heading-anchor-permalink" href="#Towards-AD-in-Julia:-Composition-of-Rules" title="Permalink"></a></h1><p>Prerequisites: <a href="../algorithmic_differentiation/#Algorithmic-Differentiation">Algorithmic Differentiation</a>.</p><p>In <a href="../rule_system/#Mooncake.jl&#39;s-Rule-System">Mooncake.jl&#39;s Rule System</a> we discuss a generic mathematical model for a Julia <code>function</code>, and state what a rule to differentiate it in reverse-mode must do. Our goal, however, is to implement an algorithm which produces rules for functions which we do not already have rules for. This section explains the mathematical model required to know how to do this.</p><h2 id="A-Motivating-Example"><a class="docs-heading-anchor" href="#A-Motivating-Example">A Motivating Example</a><a id="A-Motivating-Example-1"></a><a class="docs-heading-anchor-permalink" href="#A-Motivating-Example" title="Permalink"></a></h2><p>By the end of this section we will understand why, for the following function:</p><pre><code class="language-julia hljs">function f(x, y)
    a = g(x)
    b = h(a, y)
    return b
end</code></pre><p>the following rule is a correct implementation of reverse-mode AD for it:</p><pre><code class="language-julia hljs">function r(f, x, y)
    a, adj_g = r(g, x)
    b, adj_h = r(h, a, x, y)
    function adj_f(db)
        _, da, dx, dy = adj_h(db)
        _, dx2 = adj_g(da)
        dx = Mooncake.increment!!(dx, dx2)
        return NoRData(), dx, dy
    end
    return b, adj_f
end</code></pre><p>Observe that the above rule essentially does the following:</p><ol><li>fowards-pass: replace calls to rules.</li><li>reverse-pass: run adjoints in reverse order, adding together rdata when a variable is used multiple times.</li></ol><p>This way of writing rules is the essence of the &quot;A&quot; in &quot;AD&quot;. This page is therefore dedicated to building up to this example via a sequence of increasingly general examples. Once we have this, extending it to a <em>very</em> general class of Julia functions is comparatively straightforward.</p><p>We shall adopt the following approach to each problem:</p><ol><li>specify class of <code>function</code>s,</li><li>specify class of differentiable functions used to model these <code>function</code>s,</li><li>specify how to find the adjoints of this differentiable model, and</li><li>describe a rule system which implements these adjoints.</li></ol><p>At a high level, you can think of this approach as first &quot;mathematising&quot; the problem, applying the techniques developed in <a href="../algorithmic_differentiation/#Algorithmic-Differentiation">Algorithmic Differentiation</a> to determine what it is that AD must do, and then providing an outline for implementing this model as a computer programme.</p><h2 id="Part-1:-Simple-Compositions-of-Pure-Functions"><a class="docs-heading-anchor" href="#Part-1:-Simple-Compositions-of-Pure-Functions">Part 1: Simple Compositions of Pure Functions</a><a id="Part-1:-Simple-Compositions-of-Pure-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Part-1:-Simple-Compositions-of-Pure-Functions" title="Permalink"></a></h2><p>For this class of <code>function</code>s, the translation between the Julia <code>function</code> and differentiable function used to model it is almost trivial. We ask for patience, and promise that the modelling task will become more interesting shortly!</p><h3 id="function-Class"><a class="docs-heading-anchor" href="#function-Class"><code>function</code> Class</a><a id="function-Class-1"></a><a class="docs-heading-anchor-permalink" href="#function-Class" title="Permalink"></a></h3><p>To start with, let us consider only <code>function</code>s which are pure (free of externally-visible side effects, such as the modification of their arguments of global variables), unary (single-argument), and don&#39;t contain any data themselves (e.g. no closures or callable <code>struct</code>s). For example, consider:</p><h4 id="g:"><a class="docs-heading-anchor" href="#g:"><code>g</code>:</a><a id="g:-1"></a><a class="docs-heading-anchor-permalink" href="#g:" title="Permalink"></a></h4><p><code>g(x::Vector{Float64}) = 2x</code> TODO: pick a non-linear example!!!!</p><h4 id="h:"><a class="docs-heading-anchor" href="#h:"><code>h</code>:</a><a id="h:-1"></a><a class="docs-heading-anchor-permalink" href="#h:" title="Permalink"></a></h4><p><code>h(x::Matrix{Float64}) = sum(x)</code>.</p><h4 id="Composition"><a class="docs-heading-anchor" href="#Composition">Composition</a><a id="Composition-1"></a><a class="docs-heading-anchor-permalink" href="#Composition" title="Permalink"></a></h4><p>Let <code>f</code> be the composition of <code>f_1, ..., f_N</code>, a collection of <code>N</code> Julia <code>function</code>s which are pure and unary. This might be implemented as <code>f(x) := f_N ∘ ... ∘ f_1</code>, or perhaps</p><pre><code class="language-julia hljs">function f(x)
    x_1 = x
    x_2 = f_1(x_1)
    ...
    return f_N(x_N)
end</code></pre><p>There are many ways to implement this function.</p><h3 id="Differentiable-Model"><a class="docs-heading-anchor" href="#Differentiable-Model">Differentiable Model</a><a id="Differentiable-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Differentiable-Model" title="Permalink"></a></h3><p>We propose to represent any <code>function</code> <code>f</code> in this class by a differentiable function <span>$f : \mathcal{X} \to \mathcal{Y}$</span>.</p><h4 id="g:-2"><a class="docs-heading-anchor" href="#g:-2"><code>g</code>:</a><a class="docs-heading-anchor-permalink" href="#g:-2" title="Permalink"></a></h4><p>Let <span>$\mathcal{X} = \mathcal{Y} =: \mathbb{R}^D$</span> where <span>$D$</span> is <code>length(x)</code>, and <span>$f(x) := 2x$</span>.</p><h4 id="h:-2"><a class="docs-heading-anchor" href="#h:-2"><code>h</code>:</a><a class="docs-heading-anchor-permalink" href="#h:-2" title="Permalink"></a></h4><p>Let <span>$\mathcal{X} := \mathbb{R}^{P \times Q}$</span>, and <span>$\mathcal{Y} := \mathbb{R}$</span>, where <span>$P$</span> and <span>$Q$</span> are the number of rows and columns in <code>x</code>, and <span>$f(x) := \sum_{p,q} x_{p,q}$</span>.</p><h4 id="Composition:"><a class="docs-heading-anchor" href="#Composition:">Composition:</a><a id="Composition:-1"></a><a class="docs-heading-anchor-permalink" href="#Composition:" title="Permalink"></a></h4><p>Let <span>$f_n : \mathcal{X}_n \to \mathcal{X}_{n+1}$</span> be the differentiable model for <code>f_n</code>. Then the differentiable model <span>$f : \mathcal{X} \to \mathcal{Y}$</span> for <code>f</code> is <span>$f := f_N \circ \dots \circ f_1$</span>, with <span>$\mathcal{X} := \mathcal{X}_1$</span> and <span>$\mathcal{Y} := \mathcal{X}_{N+1}$</span>.</p><h3 id="Adjoints-of-Model"><a class="docs-heading-anchor" href="#Adjoints-of-Model">Adjoints of Model</a><a id="Adjoints-of-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Adjoints-of-Model" title="Permalink"></a></h3><p>You can apply the tools developed in <a href="../algorithmic_differentiation/#Algorithmic-Differentiation">Algorithmic Differentiation</a> to figure out the adjoints of <code>g</code> and <code>h</code>. The adjoint of <code>f</code> is also given there. Let <span>$D f_n [x_n]^\ast$</span> be the adjoint of the derivative of <span>$f_n$</span> at <span>$x_n$</span>, then the adjoint of <span>$f$</span> at <span>$x$</span> is just</p><p class="math-container">\[D f [x]^\ast = D f_1 [x_1]^\ast \circ \dots \circ D f_N [x_N]^\ast.\]</p><h3 id="Rules"><a class="docs-heading-anchor" href="#Rules">Rules</a><a id="Rules-1"></a><a class="docs-heading-anchor-permalink" href="#Rules" title="Permalink"></a></h3><p>For this simple class of functions, a simple rule system will do. We require that a rule for a <code>function</code> with mathematical model <span>$f$</span> accepts the same argument as the original <code>function</code>, and returns a 2-tuple containing</p><ol><li>the result of applying the <code>function</code> to its input, and</li><li>another function which implements<sup class="footnote-reference"><a id="citeref-implementing_mathematics_on_a_computer" href="#footnote-implementing_mathematics_on_a_computer">[implementing_mathematics_on_a_computer]</a></sup> the adjoint, i.e. <span>$D f [x]^\ast$</span>.</li></ol><p>Given a rule for a <code>function</code> of interest, we simply run the rule, and can then apply the adjoint to any gradient vector of interest.</p><h4 id="g:-3"><a class="docs-heading-anchor" href="#g:-3"><code>g</code>:</a><a class="docs-heading-anchor-permalink" href="#g:-3" title="Permalink"></a></h4><pre><code class="language-julia hljs">function rrule(::typeof(g), x::Vector{Float64})
    g_adjoint(ȳ::Vector{Float64}) = 2ȳ
    return g(x), g_adjoint
end</code></pre><h4 id="h:-3"><a class="docs-heading-anchor" href="#h:-3"><code>h</code>:</a><a class="docs-heading-anchor-permalink" href="#h:-3" title="Permalink"></a></h4><pre><code class="language-julia hljs">function rrule(::typeof(h), x::Matrix{Float64})
    h_adjoint(ȳ::Float64) = fill(ȳ, size(x))
    return h(x), h_adjoint
end</code></pre><h4 id="Composition:-2"><a class="docs-heading-anchor" href="#Composition:-2">Composition:</a><a class="docs-heading-anchor-permalink" href="#Composition:-2" title="Permalink"></a></h4><p>One possible implementation for a rule for the composition of <code>f_1, ..., f_N</code> is</p><pre><code class="language-julia hljs">function rrule(::typeof(f), x)
    x_1 = x
    x_2, f_1_adjoint = rrule(f_1, x_1)
    ...
    y, f_N_adjoint = rrule(f_N, x_N)
    function f_adjoint(ȳ)
        x̄_N = f_N_adjoint(ȳ)
        ...
        x̄_1 = f_1_adjoint(x̄_2)
        x̄ = x̄_1
        return x̄
    end
    return y, f_adjoint
end</code></pre><p>You should convince yourself that this does indeed return a 2-tuple satisfying the specification above.</p><h2 id="Part-2:-Functions-of-Pure-Functions"><a class="docs-heading-anchor" href="#Part-2:-Functions-of-Pure-Functions">Part 2: Functions of Pure Functions</a><a id="Part-2:-Functions-of-Pure-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Part-2:-Functions-of-Pure-Functions" title="Permalink"></a></h2><p>The previous example demonstrated how we might treat a composition of pure <code>function</code>s of a single argument. Here, we extend this to pure <code>function</code>s of multiple arguments.</p><h3 id="Class-of-functions"><a class="docs-heading-anchor" href="#Class-of-functions">Class of <code>function</code>s</a><a id="Class-of-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Class-of-functions" title="Permalink"></a></h3><p>To see an example of this, consider the following computation graph:</p><p><img src="../../assets/computation_graph.png" alt="linear_regression"/></p><p>It describes the loss function associated to linear regression, and might be written as Julia code in the following way:</p><pre><code class="language-julia hljs">function linear_regression_loss(W, X, Y)
    Y_hat = X * W
    eps = Y - Y_hat
    l = dot(eps, eps)
    return l
end</code></pre><p>As before, in order to produce a precise mathematical model for this Julia <code>function</code>, we reduce it to the composition of elementary functions. However, in order to do so, we will have to be a little more creative in how we choose these functions.</p><h3 id="Differentiable-Mathematical-Model"><a class="docs-heading-anchor" href="#Differentiable-Mathematical-Model">Differentiable Mathematical Model</a><a id="Differentiable-Mathematical-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Differentiable-Mathematical-Model" title="Permalink"></a></h3><p>We model this <code>function</code> as a function <span>$f$</span> defined as follows:</p><p class="math-container">\[\begin{align}
    f :=&amp;\, r \circ \varphi_3 \circ \varphi_2 \circ \varphi_1 \textrm{ where } \nonumber \\
    \varphi_1(W, X, Y) :=&amp;\, (W, X, Y, XW) \nonumber \\
    \varphi_2(W, X, Y, \hat{Y}) :=&amp;\, (W, X, Y, \hat{Y}, Y - \hat{Y}) \nonumber \\
    \varphi_3(W, X, Y, \hat{Y}, \varepsilon) :=&amp;\, (W, X, Y, \hat{Y}, \varepsilon, \|\varepsilon\|_2^2) \nonumber \\
    r(W, X, Y, \hat{Y}, \varepsilon, l) :=&amp;\, l \nonumber
\end{align}\]</p><p>In words, our mathematical model for <code>linear_regression_loss</code> is the composition of four differentiable functions. The first three map from a tuple containing all variables seen so far, to a tuple containing the same variables <em>and</em> the value returned by the operation being modeled, and the fourth simple reads off the elements of the final tuple which were passed in as arguments, and the return value.</p><p>In general, we model the <span>$n$</span>th Julia <code>function</code> <em>call</em> with a function <span>$\varphi_n$</span> mapping from a tuple of <span>$D$</span> elements to a tuple of <span>$D + 1$</span> elements, of the form</p><p class="math-container">\[\varphi_n(x) := (x_1, \dots, x_D, g_n (a_n(x)))\]</p><p>for some differentiable function <span>$g_n$</span>, and &quot;argument selector&quot; function <span>$a_n$</span>. In words: each function call involves</p><ol><li>preparing the arguments to be passed to the function call, (<span>$a_n$</span>)</li><li>calling the function (<span>$g_n$</span>), and</li><li>adding a new variable to the list of in-scope variables (new tuple is of length <span>$D + 1$</span>).</li></ol><p>For example, in the case of our example above,</p><p class="math-container">\[\begin{align}
    &amp;\varphi_1:\quad a_1(x) := (x_2, x_1)  &amp;\text{ and   } \quad &amp;g_1(A,B) := AB \nonumber \\
    &amp;\varphi_2:\quad a_2(x) := (x_3, x_4)  &amp;\text{ and   } \quad &amp;g_2(A,B) := A - B \nonumber \\
    &amp;\varphi_3:\quad a_3(x) := x_5         &amp;\text{ and   } \quad &amp;g_3(A) := \|A\|_2^2 \nonumber
\end{align}\]</p><p>Note that the argument to <span>$a_1$</span> is a 3-tuple, to <span>$a_2$</span> a 4-tuple, and to <span>$a_3$</span> a 5-tuple. Crucially, observe that <span>$f$</span> has exactly the same structure as <span>$g_1$</span>, <span>$g_2$</span>, and <span>$g_3$</span> – it maps from the tuple containing its arguments to its <code>return</code> value. This gives us a recursive structure which is essential for making AD work.</p><p><span>$r$</span> always just maps from a tuple to the last element of that tuple.</p><h3 id="Differentiating-the-Mathematical-Model"><a class="docs-heading-anchor" href="#Differentiating-the-Mathematical-Model">Differentiating the Mathematical Model</a><a id="Differentiating-the-Mathematical-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Differentiating-the-Mathematical-Model" title="Permalink"></a></h3><p>Dropping the subscript <span>$n$</span>, functions such as <span>$\varphi$</span> have derivative</p><p class="math-container">\[D [\varphi, x] (\dot{x}) = (\dot{x}_1, \dots, \dot{x}_D, D [g \circ a, x] (\dot{x})).\]</p><p>Letting <span>$\bar{y} := (\bar{y}_1, \dots \bar{y}_{D+1})$</span>, we can perform the usual manipulations to find the adjoint of <span>$D[\varphi, x]$</span>:</p><p class="math-container">\[\begin{align}
    \langle \bar{y}, D[\varphi, x](\dot{x}) \rangle &amp;= \langle (\bar{y}_1, \dots, \bar{y}_{D+1}), (\dot{x}_1, \dots, \dot{x}_D, D[g \circ a, x](\dot{x})) \rangle \nonumber \\
        &amp;= \sum_{d=1}^D \langle \bar{y}_d, \dot{x}_d \rangle + \langle D[g \circ a, x]^\ast (\bar{y}_{D+1}), \dot{x} \rangle \nonumber \\
        &amp;= \langle (\bar{y}_1, \dots, \bar{y}_D), \dot{x} \rangle + \langle D[g \circ a, x]^\ast (\bar{y}_{D+1}), \dot{x} \rangle \nonumber \\
        &amp;= \langle (\bar{y}_1, \dots, \bar{y}_D) + D[g \circ a, x]^\ast (\bar{y}_{D+1}), \dot{x} \rangle. \nonumber
\end{align}\]</p><p>So, what is <span>$D[g \circ a, x]^\ast (\bar{y}_{D+1})$</span>?. First let <span>$z := a(x)$</span> and observe that <span>$D[a, x] = a$</span> since <span>$a$</span> is linear. It follows that</p><p class="math-container">\[D[g \circ a, x]^\ast = (D[g, z] \circ D[a, x])^\ast = (D[g, z] \circ a)^\ast = a^\ast \circ D[g, z]^\ast .\]</p><p>Since <span>$g$</span> has the same form as <span>$f$</span>, assume that we know <span>$D[g, z]^\ast$</span> by induction. An expression for <span>$a^\ast$</span>, on the other hand, we obtain from its definition directly.</p><p>As discussed <span>$a$</span> maps from a tuple containing all variables passed in to <span>$f$</span>, to the tuple which is to be passed to <span>$g$</span>. For example, suppose variables <code>x_1, x_2, x_3</code> are in-scope, then a call of the form</p><ol><li><code>g(x_2, x_1)</code> has argument selector <span>$a(x) := (x_2, x_1)$</span>, and</li><li><code>g(x_3, x_3)</code> has argument selector <span>$a(x) := (x_3, x_3)$</span>,</li></ol><p>where <span>$x$</span> is a 3-tuple in both examples. The general form of an argument selector <span>$a$</span> mapping from a <span>$D$</span>-tuple to an <span>$N$</span>-tuple is</p><p class="math-container">\[a(x) = (x_{i_1}, \dots, x_{i_N})\]</p><p>for some set of integers <span>$i_1, \dots, i_N \in \{1, \dots, D\}$</span>. Let <span>$z = (z_1, \dots, z_N)$</span>, and <span>$c_n(z)$</span> the <span>$D$</span>-tuple which is equal to <span>$z_n$</span> at element <span>$i_n$</span>, and zero everywhere else. Then adjoint of <span>$a$</span> is obtained in the usual manner:</p><p class="math-container">\[\begin{align}
\langle z, a^\ast (x) \rangle &amp;= \langle (z_1, \dots, z_N), (x_{i_1}, \dots, x_{i_N}) \rangle = \sum_{n=1}^N \langle z_n, x_{i_n} \rangle = \sum_{n=1}^N \langle c_n(z), x \rangle = \langle \sum_{n=1}^N c_n(z), x \rangle, \nonumber
\end{align}\]</p><p>from which we conclude</p><p class="math-container">\[a^\ast(z) = \sum_{n=1}^N c_n(z). \nonumber\]</p><p>Applying this result to our previous examples, we see that</p><ol><li>when <span>$a(x) := (x_2, x_1)$</span>, <span>$a^\ast (z) := (z_2, z_1, 0)$</span>, and that</li><li>when <span>$a(x) := (x_3, x_3)$</span>, <span>$a^\ast (z) := (0, 0, z_1 + z_2)$</span>.</li></ol><p>Combining this result with the adjoint of the derivative of <span>$\varphi$</span> yields</p><p class="math-container">\[D[\varphi, x]^\ast (\bar{y}) = (\bar{y}_1, \dots, \bar{y}_D) + \sum_{n=1}^N c_n(D [g, z]^\ast (\bar{y})).\]</p><p>We must also find the derivative of the adjoint of <span>$r$</span>. It is linear, so it is its own derivative. Assume <span>$f$</span> is of the form</p><p class="math-container">\[f = r \circ \varphi_P \circ \dots \circ \varphi_1\]</p><p>and that its arguments are <span>$N$</span>-tuples. Then <span>$r$</span> maps from <span>$(N + P)$</span>-tuples to a single value, and its adjoint is a tuple of length <span>$N + P$</span> given by</p><p class="math-container">\[r^\ast(\bar{y}) = (0, \dots, 0, \bar{y}_{N+1}).\]</p><p>Finally, the adjoint the derivative of <span>$f$</span> is</p><p class="math-container">\[D [f,x]^\ast = D[\varphi_1, x_1]^\ast \circ \dots \circ D [\varphi_P, x_P]^\ast \circ r^\ast\]</p><p>where <span>$x_p := \varphi_{p-1}(x_{p-1})$</span> and <span>$x_1 := x$</span>. Since we now have expressions for all of the terms in this, we consider how to produce a programme which implements this adjoint.</p><h3 id="Implementation"><a class="docs-heading-anchor" href="#Implementation">Implementation</a><a id="Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation" title="Permalink"></a></h3><p>We start by revisiting our Julia <code>function</code> which computes the loss associated to linear regression, as it is easiest to start with a concrete example:</p><pre><code class="language-julia hljs">function f(W, X, Y)
    Y_hat = X * W
    eps = Y - Y_hat
    l = dot(eps, eps)
    return l
end</code></pre><p>Let the function <code>rule</code> map from a <code>function</code> and its arguments to a 2-tuple comprising the return value of that function, and a closure which computes the adjoint. The closure maps from a gradient vector, associated to the return value of the function, to a tuple containing the gradient vectors associated to each of the arguments to the function.</p><p>Assume that we have methods of <code>rule</code> for <code>*</code>, <code>-</code>, and <code>dot</code>, then a possible implementation of <code>rule</code> for <code>f</code> is</p><pre><code class="language-julia hljs">function rule(f, W, X, Y)
    Y_hat, adjoint_mul = rule(*, X, W)
    eps, adjoint_minus = rule(-, Y, Y_hat)
    l, adjoint_dot = rule(dot, eps, eps)
    function adjoint_f(dout)

        # Implement adjoint of r. Assume that we have a way to produce zero gradients.
        dl = dout
        deps = zero_gradient(eps)
        dY_hat = zero_gradient(Y_hat)
        dY = zero_gradient(Y)
        dX = zero_gradient(X)
        dW = zero_gradient(W)

        # Run adjoint of `dot`.
        (deps_inc_1, deps_inc_2) = adjoint_dot(dl)

        # Run adjoint of argument selector for the call to `dot`.
        # Observe that the gradient w.r.t. `eps` gets incremented twice, because `eps`
        # appears twice in the argument list to `dot`. This is consistent with the
        # argument selector adjoint.
        deps = deps + deps_inc_1
        deps = deps + deps_inc_2

        # Run adjoint of `-`.
        (dY_inc, dY_hat_inc) = adjoint_minus(deps)
    
        # Run adjoint of argument selector for the call to `-`.
        dY = dY + dY_inc
        dY_hat = dY_hat + dY_hat_inc

        # Run adjoint of `*`.
        (dX_inc, dW_inc) = adjoint_mul(dY_hat)

        # Run adjoint of argument selector for the call to `*`.
        dX = dX + dX_inc
        dW = dW + dW_inc

        # Return the gradients w.r.t. the arguments.
        return dW, dX, dY
    end
    return l, adjoint_f
end</code></pre><p>At a high-level, rule derivation in the general case proceeds as follows. First, replace all calls in the original function with calls to <code>rule</code>s. Then define a closure which accepts a single argument. This closure first implements the adjoint of <span>$r$</span>, by assigning the argument to the closure to be the gradient of the primal <code>return</code> value, and setting the gradient of all other variables to zero. Subsequently, for each call in the primal function, in reverse order, apply the adjoint returned by the associated rule, and apply the adjoint of the argument selector associated to the call by incrementing the value of the gradients of its arguments. Finally, return a tuple containing the gradients w.r.t. each of the arguments to the primal function.</p><p>There are other equivalent ways to implement the above – see e.g. <a href="#Zygote-Implementation">Zygote Implementation</a> below. If nothing else, the derivations in this section provide a clear route to explain what goes on there.</p><p>At this point, we have enough to understand the bulk of many AD systems. If you squint, the above provides a good starting point from which to understand what <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a>, <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff.jl</a>, <a href="https://pytorch.org">PyTorch</a>, and <a href="https://github.com/jax-ml/jax">JAX</a> do, albeit each of these systems has their own particular way of achieving the above (JAX in particular). The defining property of each of these systems is that they (for the most part) involve pure-functions.</p><h2 id="Part-3:-Applying-Sequences-of-Mutating-Functions"><a class="docs-heading-anchor" href="#Part-3:-Applying-Sequences-of-Mutating-Functions">Part 3: Applying Sequences of Mutating Functions</a><a id="Part-3:-Applying-Sequences-of-Mutating-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Part-3:-Applying-Sequences-of-Mutating-Functions" title="Permalink"></a></h2><p>Julia <code>function</code> can modify their inputs. For example, consider</p><pre><code class="language-julia hljs">function f!(x::Vector{Float64})
    x .= 2 .* x
    return nothing
end</code></pre><p>This <code>function</code> mutates (modifies / changes) the values stored in each element of <code>x</code>. In order to model this kind of behaviour, we introduce the notion of state, as discussed in <a href="../rule_system/#Mooncake.jl&#39;s-Rule-System">Mooncake.jl&#39;s Rule System</a>. In particular, we associate to <code>f!</code> a differentiable function <span>$f : \mathcal{X} \to \mathcal{X}$</span>, defined such that if <code>x</code> is associated to value <span>$x$</span> prior to running <code>f!</code>, it has value <span>$f(x)$</span> after running <code>f!</code>. We call <span>$f$</span> the <em>transition</em> <em>function</em> associated to <code>f!</code>. We now have something to differentiate.</p><p>We first study <code>function</code>s of the following form:</p><pre><code class="language-julia hljs">function f!(x::Vector{Float64})
    f_1!(x)
    f_2!(x)
    ...
    f_N!(x)
    return nothing
end</code></pre><p>We associate to each <code>f_n!</code> its transition function <span>$f_n : \mathcal{X} \to \mathcal{X}$</span>, where <span>$\mathcal{X} := \mathbb{R}^D$</span> (assume for now that the <code>length(x)</code> is not modified by any of the operations). The transition function <span>$f$</span> associated to <code>f</code> is simply</p><p class="math-container">\[f := f_N \circ \dots \circ f_1\]</p><h2 id="Part-4:-Computational-Graphs-of-Mutating-Functions"><a class="docs-heading-anchor" href="#Part-4:-Computational-Graphs-of-Mutating-Functions">Part 4: Computational Graphs of Mutating Functions</a><a id="Part-4:-Computational-Graphs-of-Mutating-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Part-4:-Computational-Graphs-of-Mutating-Functions" title="Permalink"></a></h2><h2 id="Part-5:-Computational-Graphs-of-Mutating-Functions-with-Aliasing"><a class="docs-heading-anchor" href="#Part-5:-Computational-Graphs-of-Mutating-Functions-with-Aliasing">Part 5: Computational Graphs of Mutating Functions with Aliasing</a><a id="Part-5:-Computational-Graphs-of-Mutating-Functions-with-Aliasing-1"></a><a class="docs-heading-anchor-permalink" href="#Part-5:-Computational-Graphs-of-Mutating-Functions-with-Aliasing" title="Permalink"></a></h2><h3 id="Zygote-Implementation"><a class="docs-heading-anchor" href="#Zygote-Implementation">Zygote Implementation</a><a id="Zygote-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Zygote-Implementation" title="Permalink"></a></h3><p>For example, rather than incrementing gradients immediately after calls to adjoints, <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a> adds together the gradients of a variable immediately before the gradient is used. The implementation of adjoint produced by Zygote is, roughly speaking, something like</p><pre><code class="language-julia hljs">function rule(f, W, X, Y)
    Y_hat, adjoint_mul = rule(*, X, W)
    eps, adjoint_minus = rule(-, Y, Y_hat)
    l, adjoint_dot = rule(dot, eps, eps)
    function adjoint_f(dout)

        # Implement adjoint of r. Assume that we have a way to produce zero gradients.
        dl = dout

        # Run adjoint of `dot`.
        (deps_1, deps_2) = adjoint_dot(dl)

        # Run adjoint of `-`.
        deps = deps_1 + deps_2
        (dY, dY_hat) = adjoint_minus(deps)
    
        # Run adjoint of `*`.
        (dX, dW) = adjoint_mul(dY_hat)

        # Return the gradients w.r.t. the arguments.
        return dW, dX, dY
    end
    return l, adjoint_f
end</code></pre><p>It computes the same thing as discussed previously, but avoids redundant calls to <code>zero_gradient</code> and <code>+</code>.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-implementing_mathematics_on_a_computer"><a class="tag is-link" href="#citeref-implementing_mathematics_on_a_computer">implementing_mathematics_on_a_computer</a>put differently, suppose that someone wrote down some equations in a paper or textbook, and gave you a piece of code which they claim is an implementation of these equations (e.g. a neural network, a probabilistic model, an ODE, etc). Under what conditions would you be satisfied that the implementation was correct? We all do this in informal ways all of the time. I propose that you apply the same set of standards here: we have written down some equations for the adjoints, and are claiming that our rule system is an implementation of these. The fact that we arrived at this set of equations by modelling a computer programme is neither here nor there for this step of the process.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../rule_system/">« Mooncake.jl&#39;s Rule System</a><a class="docs-footer-nextpage" href="../../utilities/defining_rules/">Defining Rules »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Friday 14 March 2025 10:45">Friday 14 March 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
